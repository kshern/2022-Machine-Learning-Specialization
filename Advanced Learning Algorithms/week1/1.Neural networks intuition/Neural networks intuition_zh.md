# Neural networks intuition

## Welcome!
欢迎来到这个机器学习专业的第二门课程。在本课程中，您将学习神经网络，也称为深度学习算法，以及决策树。它们是一些最强大和广泛使用的机器学习算法，您将学习如何实现它们并使它们为您工作。本课程的另一个亮点是提供了关于如何构建机器学习系统的实用建议。当您构建实际的机器学习系统时，需要做出许多决策，例如您应该花更多时间收集数据还是购买更大的GPU来构建更大的神经网络？即使在今天，当我访问一家领先的技术公司并与他们正在处理机器学习应用的团队交谈时，有时我会看看他们在过去六个月中所做的事情，然后想，天哪，也许甚至六个月前有人就应该告诉你，那种方法可能不会那么有效。通过本课程学习到的一些技巧，我希望您能成为那些不浪费这六个月时间的人之一，而是能够更系统地和更好地决策如何构建实际工作的机器学习应用程序。接下来，让我们深入了解本课程的四个星期内容。在第一周，我们将介绍神经网络以及如何进行推理或预测。如果您要去互联网上下载另一个人训练的神经网络的参数，并使用该神经网络进行预测，那么这将被称为推理。在这一周中，您将学习神经网络的工作方式以及如何进行推理。下一周，您将学习如何训练自己的神经网络。特别是，如果您有一个带有标记示例 X 和 Y 的训练集，您将学习如何为自己训练神经网络的参数。在第三周中，我们将进入构建机器学习系统的实用建议，并分享我认为即使是今天非常成功地构建机器学习系统的高薪工程师也不一定始终能够持续应用的一些技巧，我认为这将帮助您高效快速地构建系统。然后，在本课程的最后一周，您将学习有关决策树的知识。虽然决策树在媒体上不像神经网络那样受到炒作，但它们也是广泛使用的非常强大的学习算法之一，我认为如果您最终构建应用程序，有很大的机会会使用到它们。让我们开始学习神经网络，我们将从快速了解人脑（也就是生物大脑）的工作方式开始。现在，让我们进入下一个视频。

## Neurons and the brain

当神经网络在几十年前首次被发明时，最初的动机是编写可以模仿人类大脑或生物大脑学习和思考的软件。尽管今天的神经网络（有时也称为人工神经网络）已经与我们对大脑实际工作和学习的想法非常不同，但一些生物学上的动机仍然存在于我们今天思考人工神经网络或计算机神经网络的方式中。让我们从了解大脑如何工作以及它与神经网络的关系开始。人类大脑，或者更普遍地说，生物大脑展示了更高水平或更有能力的智能，其他任何东西都远远落后。因此，神经网络的起点是尝试构建可以模仿大脑的软件。神经网络的工作始于1950年代，然后一度不受青睐。然后在1980年代和90年代初期，神经网络再次受到欢迎，并在一些应用中表现出巨大的吸引力，如手写数字识别，甚至在那个时候就被用于读取邮政编码以编写邮件和阅读手写支票中的金额。但是，它在90年代末又失去了青睐。从2005年开始，它又重新兴起，并且也被重新品牌化为深度学习。当时让我感到惊讶的是，深度学习和神经网络的意思非常相似。但是也许当时被低估的是，深度学习这个术语听起来更好，因为它是深度和学习。因此，这成为了过去十年或十五年中风靡的品牌。从那时起，神经网络已经彻底改变了一个应用领域又一个应用领域。我认为现代神经网络或深度学习对第一个应用领域产生巨大影响的可能是语音识别，我们开始看到由于现代深度学习和作者如Hinton的贡献而变得更好的语音识别系统，然后它开始进入计算机视觉领域。

有时人们仍然会谈论2012年的ImageNet时刻，那可能是一个更大的影响，激发了人们的想象力，并对计算机视觉产生了巨大影响。接下来的几年中，它开始进军到文本或自然语言处理等领域。现在，神经网络被用于从气候变化到医学成像、在线广告到产品推荐的所有领域，现在机器学习的许多应用领域都使用神经网络。尽管今天的神经网络几乎与大脑学习无关，但早期的动机是尝试构建可以模仿大脑的软件。那么大脑是如何工作的呢？这里是一个说明大脑中神经元长什么样子的图示。所有的人类思维都来自于大脑和我的这样的神经元，它们发送电脉冲，有时形成其他神经元的新连接。对于像这样的神经元，它有许多输入，从其他神经元接收电脉冲，然后我用圆圈标出的这个神经元执行一些计算，然后通过电脉冲将输出发送给其他神经元，而上面神经元的输出又成为下面神经元的输入，下面神经元再次聚合来自多个其他神经元的输入，然后可能发送自己的输出给其他神经元，这就是人类思维的基础。这里是一个生物神经元的简化图。一个神经元由这里左边显示的细胞体组成，如果您上过生物课，您可能会认出这是神经元的细胞核。如前一张幻灯片所示，神经元具有不同的输入。在生物神经元中，输入线称为树突，然后它通过称为轴突的输出线不时向其他神经元发送电脉冲。不用担心这些生物学术语。如果您在生物课上看到它们，您可能会记得它们，但是为了构建人工神经网络，您不需要记忆任何这些术语。但是，这个生物神经元可能会发送成为另一个神经元输入的电脉冲。因此，人工神经网络使用了生物神经元的一个非常简化的数学模型。我会画一个小圆圈来表示一个单独的神经元。一个神经元的作用是接收一些输入，一个或多个输入，这些输入只是数字。它进行一些计算，然后输出一些其他数字，这些数字可能是第二个神经元的输入，如右侧所示。当构建人工神经网络或深度学习算法时，您通常不希望一次构建一个神经元，而是要同时模拟许多这样的神经元。

在这个图示中，我画了三个神经元。这些神经元的集体作用是输入一些数字，进行一些计算，然后输出一些其他数字。现在，我想要提出一个重要的警告，即使我在生物神经元和人工神经元之间进行了松散的类比，但我认为今天我们几乎不知道人脑是如何工作的。事实上，每隔几年，神经科学家都会有一些关于大脑如何工作的基本突破。我认为在可预见的未来，我们将继续做出突破。对我来说，这是一个迹象，表明有许多关于大脑实际工作方式的突破还有待发现，因此，尝试盲目模仿我们今天所知道的人脑，这实际上很少，可能不会让我们在构建原始智能方面走得太远。特别是在我们目前的神经科学知识水平下。话虽如此，即使使用这些极为简化的神经元模型，我们仍然能够构建非常强大的深度学习算法。因此，当你深入研究神经网络和深度学习时，尽管起源是受生物学启发的，但不要太认真地看待生物学的启发。事实上，我们这些研究深度学习的人已经转向使用工程原理来找出更有效的算法。但我认为偶尔思考和推测生物神经元的工作方式仍然很有趣。神经网络的思想已经存在了很多年。有些人问我：“安德鲁，为什么现在才是神经网络真正火起来的时候？”这是我为他们画的一张图片，如果别人问你这个问题，你也可以画一下。让我在水平轴上绘制解决问题所需的数据量，在垂直轴上绘制应用于该问题的学习算法的性能或准确性。在过去的几十年中，随着互联网的崛起、手机的普及、我们社会的数字化，许多应用程序的数据量不断向右增长。许多以前纸质记录的事情，例如如果你订购某物而不是在纸上，数字记录的可能性要大得多。你的健康记录，如果你去看医生，现在与纸质记录相比更可能是数字的。因此，在许多应用领域，数字数据的数量已经爆炸了。我们看到的是，对于传统的机器学习算法，例如逻辑回归和线性回归，即使你给这些算法提供更多的数据，也很难使性能继续提高。因此，传统的学习算法，如线性回归和逻辑回归，似乎无法随着我们现在可以输入的数据量的增加而扩展，也无法有效利用我们在不同应用中拥有的所有这些数据。

人工智能研究人员开始观察到的是，如果你在这个数据集上训练一个小型神经网络，那么性能可能看起来像这样。如果你训练一个中等大小的神经网络，也就是一个拥有更多神经元的神经网络，它的性能可能看起来像那样。如果你训练一个非常大的神经网络，也就是一个拥有许多这些人工神经元的神经网络，那么对于某些应用程序，性能将会不断提高。因此，这意味着两件事情，它意味着对于某一类拥有大量数据的应用程序，有时你会听到大数据这个术语，如果你能够训练一个非常大的神经网络来利用你拥有的大量数据，那么你就可以在从语音识别到图像识别，再到自然语言处理应用程序等等方面获得性能，这些先前的学习算法是不可能实现的。这导致深度学习算法开始崛起，这也是为什么更快的计算机处理器，包括GPU或图形处理器单元的崛起。这是最初设计用于生成漂亮的计算机图形的硬件，但也被证明对深度学习非常强大。这也是允许深度学习算法成为今天的原因之一。这就是神经网络的起源，以及为什么它们在过去几年中迅速崛起。现在让我们更深入地了解神经网络实际上是如何工作的。请继续观看下一个视频。

## Demand Prediction
为了说明神经网络的工作原理，让我们从一个例子开始。我们将使用需求预测的示例，其中您查看产品并尝试预测该产品是否会成为畅销品。让我们来看看。在这个例子中，您正在销售T恤，并且想知道特定T恤是否会成为畅销品，是或否，您已收集了不同价格的不同T恤的销售数据，以及哪些成为了畅销品。今天零售商使用这种类型的应用程序来更好地规划库存水平以及营销活动。如果您知道什么可能是畅销品，您将计划提前购买更多的库存。在这个例子中，输入特征x是T恤的价格，因此这是学习算法的输入。如果您应用逻辑回归来拟合一个sigmoid函数，那么您的预测输出可能会像这样，1/1加上e的负wx加b。以前，我们将此编写为f（x）作为学习算法的输出。为了为我们构建神经网络做好准备，我将更改术语，并使用字母a来表示此逻辑回归算法的输出。术语a代表激活，它实际上是来自神经科学的术语，它指的是一个神经元向下游神经元发送高输出的程度。事实证明，这个逻辑回归单元或这个小逻辑回归算法可以被看作是大脑中单个神经元的非常简化的模型。神经元所做的是将输入的价格x传递给计算公式，然后输出由此公式计算出的数字a，它输出了这件T恤成为畅销品的概率。另一种思考神经元的方式是将其视为一台微型计算机，其唯一的工作是输入一个数字或一些数字，例如一个价格，然后输出一个数字或可能是一些其他数字，这种情况下是T恤成为畅销品的概率。


正如我在之前的视频中所提到的那样，逻辑回归算法比我们大脑或你我的任何生物神经元所做的事情都要简单得多。这就是为什么人工神经网络是人脑的一个极度简化的模型。尽管在实践中，深度学习算法确实表现得非常好。根据单个神经元的描述，现在构建神经网络只需要将许多这些神经元连接起来或组合起来即可。现在让我们看一个更复杂的需求预测示例。在这个例子中，我们将有四个特征来预测T恤是否为畅销品。这些特征是T恤的价格、运费、特定T恤的营销金额以及材质质量，这是高质量的厚棉还是较低质量的材料？现在，您可能会怀疑T恤是否成为畅销品实际上取决于一些因素。首先是T恤的实惠程度。第二，潜在买家对该T恤的了解程度如何？第三是被认为是高品质的偏见或潜在偏见，称这是一件高品质的T恤。我将创建一个人工神经元来尝试估计这件T恤被认为是高度实惠的概率。实惠性主要是价格和运费的函数，因为支付的总金额是价格加上运费的总和。我们将使用一个小神经元，即逻辑回归单元，来输入价格和运费，并预测人们是否认为这是实惠的。其次，我将在这里创建另一个人工神经元来估计是否存在高度的认知度。在这种情况下，认知度主要是T恤的营销量的一个函数。最后，我将创建另一个神经元来估计人们是否认为这是高质量的，这可能主要取决于T恤的价格和材质质量。

价格是一个因素，因为不管是幸运还是不幸，如果一件T恤价格非常高，人们有时会认为它质量很高，因为它比较昂贵，而人们可能会认为它质量很好。根据可负担性、知名度和认知质量的估计，我们将这三个神经元的输出连接到右侧的另一个神经元，然后使用另一个逻辑回归单元。最终，将这三个数作为输入，并输出该T恤成为畅销产品的概率。在神经网络的术语中，我们将这三个神经元组合在一起形成一个称为"层"的组合。层是一组神经元，其输入是相同或相似的特征，并输出一些数值。左侧的这三个神经元形成一层，这就是为什么我将它们画在一起的原因，而右侧的这个单个神经元也是一层。左侧的层有三个神经元，因此一个层可以有多个神经元，也可以只有一个神经元，就像右侧的这个层一样。右侧的这个层也被称为输出层，因为这个最终神经元的输出是神经网络预测的输出概率。在神经网络的术语中，我们还将可负担性、知名度和认知质量称为激活。激活这个术语来自生物神经元，它指的是生物神经元发送高输出值或向其下游神经元发送许多电脉冲的程度。可负担性、知名度和认知质量这些数字是该层中这三个神经元的激活，而输出概率是右侧这个神经元的激活。因此，这个特定的神经网络执行以下计算：它输入四个数字，然后神经网络的这一层使用这四个数字计算新的数字，也称为激活值。然后，神经网络的最终层，即输出层，使用这三个数字计算一个数字。

在神经网络中，这个包含四个数字的列表也被称为输入层，它只是一个包含四个数字的列表。现在，我想对这个神经网络进行一点简化。到目前为止，我描述的方式是，我们必须逐个神经元地决定它从前一层接收哪些输入。例如，我们说可负担性只与价格和运费有关，认知度只与营销有关等等，但是如果你要构建一个大型神经网络，手动决定哪个神经元应该接收哪些特征作为输入将是很大的工作量。在实践中实现神经网络的方式是，某一层中的每个神经元都可以访问前一层，即输入层的每个特征值，这就是为什么我现在从每个输入特征画箭头指向中间显示的每个神经元。你可以想象，如果你想预测可负担性，它知道价格、运费、营销和材料是什么，也许你会学会忽略营销和材料，并通过适当设置参数来仅关注对可负担性最相关的特征子集。为了进一步简化符号和对这个神经网络的描述，我将把这四个输入特征写成一个向量x，并且我们将把神经网络视为由这个特征向量x组成的四个特征。这个特征向量被馈送到中间的这个层，然后计算出三个激活值。也就是说，这些数字和这三个激活值又成为另一个向量，被馈送到最终的输出层，最终输出这件T恤成为畅销产品的概率。这就是神经网络的全部内容。它有几个层，每个层都输入一个向量并输出另一个数字向量。例如，中间的这个层输入四个数字x，并输出对应于可负担性、认知度和认知质量的三个数字。为了增加一点术语，你已经看到这个层被称为输出层，这个层被称为输入层。为了给中间的这个层也起一个名字，这个中间的层被称为隐藏层。我知道这也许不是最好或最直观的名称，但这个术语是来自于拥有一个训练集时的情况。

在训练集中，你可以观察到x和y。你的数据集告诉你什么是x，什么是y，所以你得到的数据告诉你正确的输入和正确的输出。但是你的数据集并没有告诉你可负担性、认知度和认知质量的正确值。这些值是隐藏的。你在训练集中看不到它们，这就是为什么中间的这个层被称为隐藏层的原因。我想与你分享另一种思考神经网络的方式，这种方式对于我建立对神经网络的直观理解非常有用。让我覆盖掉这个图表的左半部分，看看我们剩下了什么。你在这里看到的是一个逻辑回归算法或逻辑回归单元，它以T恤的可负担性、认知度和认知质量作为输入，并使用这三个特征来估计T恤成为畅销产品的概率。这就是普通的逻辑回归。但是有意思的是，它不是使用原始特征，比如价格、运费、营销等，而是使用更好的特征，比如可负担性、认知度和认知质量，这些特征希望能更好地预测这件T恤是否会成为畅销产品。你可以将这个神经网络看作是普通的逻辑回归，但作为逻辑回归的一个版本，它可以学习自己的特征，使得准确预测变得更容易。实际上，你可能还记得之前的课程中的房价预测的示例，我们说如果你想预测房价，你可以取地块的正面或宽度乘以地块的深度来构建一个更复杂的特征，即x_1乘以x_2，也就是草坪的大小。在那个例子中，我们手动进行特征工程，需要查看特征x_1和x_2，并手动决定如何将它们组合在一起以得到更好的特征。而神经网络所做的是，它可以学习自己的特征，而不需要你手动进行特征工程，正如你后面将看到的那样，这使得学习问题对于神经网络本身来说更容易。这就是为什么神经网络是当今世界上最强大的学习算法之一的原因。总结一下，神经网络是这样工作的：输入层接收一个特征向量，例如这个例子中的四个数字，然后输入到隐藏层，隐藏层输出三个数字。我将使用一个向量来表示隐藏层输出的激活向量。然后输出层以隐藏层的输出作为输入，接收三个数字并输出一个数字，这将是神经网络的最终激活或最终预测。

在先前的描述中，我将这个神经网络描述为计算可负担性、认知度和认知质量，但神经网络的一个非常好的特性是，当你从数据中训练它时，你不需要明确地决定神经网络应该计算哪些其他特征，比如可负担性等等，它可以自己决定在这个隐藏层中要使用哪些特征。这就是它成为强大学习算法的原因。你在这里看到了一个神经网络的例子，这个神经网络有一个隐藏层。让我们看一下其他多层隐藏层的神经网络的例子。这是一个例子。这个神经网络有一个输入特征向量X，输入到一个隐藏层。我将它称为第一个隐藏层。如果这个隐藏层有三个神经元，那么它将输出一个由三个激活值组成的向量。这三个数字可以作为输入传递给第二个隐藏层。如果第二个隐藏层有两个神经元或逻辑单元，那么这个第二个隐藏层将输出另一个由两个激活值组成的向量，可能被传递到输出层，然后输出神经网络的最终预测。这是另一个例子。这是一个神经网络，它的输入经过第一个隐藏层，第一个隐藏层的输出经过第二个隐藏层，然后经过第三个隐藏层，最后到达输出层。在构建自己的神经网络时，你需要决定你想要多少个隐藏层，每个隐藏层要有多少个神经元。这个问题涉及神经网络的结构。在本课程的后面，你将学习到一些选择适当的神经网络结构的技巧。但是选择正确的隐藏层数和每层的隐藏单元数量也会对学习算法的性能产生影响。在本课程的后面，你还将学习如何为你的神经网络选择一个好的结构。顺便说一下，在一些文献中，你会看到这种具有多个层的神经网络被称为多层感知器。如果你看到这个术语，它只是指一个看起来像幻灯片上所示的神经网络。这就是一个神经网络。我知道这个视频中有很多内容。感谢你一直陪伴着我。但是现在你知道了神经网络的工作原理。在下一个视频中，让我们看看这些思想如何应用于其他应用程序。特别是，我们将研究人脸识别这个计算机视觉应用。让我们继续下一个视频。

## Recognizing Images

在上一个视频中，你看到了神经网络在需求预测示例中的工作原理。现在让我们看看如何将类似的思想应用于计算机视觉应用中。让我们深入了解一下。如果你正在构建一个人脸识别应用程序，你可能希望训练一个神经网络，它以这样一张图片作为输入，并输出图片中人物的身份信息。这张图片是1000x1000像素的。它在计算机中的表示实际上是一个1000x1000的网格，也称为1000x1000的像素强度值矩阵。在这个例子中，我的像素强度值或像素亮度值范围是0-255，所以这里的197是图片左上角像素的亮度，185是向右移动一个像素的亮度，依此类推，214则是图片右下角的亮度。如果你将这些像素强度值展开成一个向量，你将得到一个包含一百万个像素强度值的列表或向量。一百万是因为1000乘以1000的平方等于一百万。

人脸识别问题是这样的：你能否训练一个神经网络，它以包含一百万个像素亮度值的特征向量作为输入，并输出图片中人物的身份信息。下面是你可以构建用于完成这个任务的神经网络的方式。输入图像X被馈送到这一层的神经元中。这是第一个隐藏层，它提取一些特征。第一个隐藏层的输出被馈送到第二个隐藏层，然后输出被馈送到第三个层，最后到达输出层，该层估计图片是某个特定人物的概率。有趣的是，如果你观察一个经过大量人脸图像训练的神经网络，并尝试可视化这些隐藏层正在计算什么，你可能会发现以下内容。


在第一个隐藏层中，你可能会发现一个神经元正在寻找低垂直线或类似的垂直边缘。第二个神经元正在寻找一个倾斜的线条或倾斜的边缘。第三个神经元正在寻找该方向上的线条，以此类推。在神经网络的最早层中，你可能会发现神经元在图像中正在寻找非常短的线条或边缘。如果你观察下一个隐藏层，你会发现这些神经元可能会学会将许多小的短线和小的短边缘段组合在一起，以便寻找人脸的各个部分。例如，每个小方框就是这个神经元试图检测的内容的可视化。第一个神经元似乎在试图检测图像中某个位置是否存在眼睛。第二个神经元似乎在试图检测鼻子的一个角落，而这里的神经元可能在试图检测耳朵的底部。然后，在观察这个例子中的下一个隐藏层时，神经网络将不同的人脸部分聚合在一起，然后尝试检测更大、更粗糙的人脸形状的存在与否。最后，通过检测人脸与不同人脸形状的相似程度，神经网络创建了一组丰富的特征，这有助于输出层确定图片中人物的身份。神经网络的一个显著特点是，它可以自行学习这些特征检测器，位于不同隐藏层中。


在这个例子中，没有人告诉神经网络在第一层寻找短小的边缘，在第二层寻找眼睛、鼻子和人脸部分，然后在第三层寻找更完整的人脸形状。神经网络能够自行从数据中找出这些特征。需要注意的是，在这个可视化中，第一个隐藏层中的神经元被显示为查看相对较小的窗口以寻找这些边缘。第二个隐藏层查看更大的窗口，第三个隐藏层查看的是更大的窗口。这些小神经元的可视化实际上对应于图像中不同大小的区域。只是为了好玩，让我们看看如果你用不同的数据集来训练这个神经网络，比如大量关于汽车的图片，会发生什么。相同的学习算法要求它检测汽车，它将在第一层学习边缘，相当相似，但然后它们将学习检测汽车的部分在第二个隐藏层，然后在第三个隐藏层学习更完整的汽车形状。只需提供不同的数据，神经网络就会自动学习检测非常不同的特征，以尝试对汽车检测、人物识别或其他特定任务进行预测。这就是神经网络在计算机视觉应用中的工作原理。

实际上，在本周晚些时候，您将看到如何亲自构建一个神经网络并将其应用于手写数字识别应用程序。到目前为止，我们一直在描述神经网络的直观原理，以使您对其工作方式有所了解。在下一个视频中，让我们更深入地研究具体的数学和具体的实现细节，以了解如何实际构建一个或多个神经网络层，以及您如何亲自实现这些内容。让我们继续下一个视频。

